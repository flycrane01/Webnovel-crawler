#!/usr/bin/env python3.6

""" A simple webnovel crawler."""
# TODO: 1.考虑exception问题 2.多线程？

from selenium import webdriver
from bs4 import BeautifulSoup
import urllib.request
import time
import os
import re


def namemodifier(string):
    string = string.replace('\\','')
    string = string.replace('/','')
    string = string.replace(':','')
    string = string.replace('*','')
    string = string.replace('"','')
    string = string.replace('<','')
    string = string.replace('>','')
    string = string.replace('|','')
    string = string.replace('?','')
    return string


def now():
    t = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    return t+' '


if __name__ == '__main__':
    while True:
        print('Enter the absolute URL of the cover page of the novel that you want to download')
        print('Example: https://www.webnovel.com/book/8335353205000005/Mystical-Journey')
        link = input()
        if 'www.webnovel.com/book' in link:
            break
        print('Please double check your URL.')

    # get the table of contents
    print(now()+'Initializing the virtual browser... Might take a while')
    browser = webdriver.PhantomJS()
    browser.get(link)
    booktitle = namemodifier(browser.title.split(' - ')[0])
    print(now()+'Book name: %s' % booktitle)
    print(now()+'Locating the contents page...')
    browser.find_element_by_class_name('j_show_contents').click()
    time.sleep(5)
    pattern = re.compile(r'''<p class="ell dib vam">.*?>.*?>(.*?)<.*?</strong>.*?>(.*?)<.*?</strong>.*?>(.*?)<''',re.S)
    bookinfo = re.findall(pattern,browser.page_source)[0]
    contents = browser.find_elements_by_xpath("//a[@class='c_strong vam ell db pr']")
    print(now()+'Retrieving table of contents')
    links = [i.get_attribute('href') for i in contents]
    browser.quit()

    # start real work
    os.mkdir(booktitle)
    os.chdir(booktitle)
    book = open(booktitle+'.txt','a+',encoding='utf-8')
    readme = open('readme.log','a+',encoding='utf-8')
    os.mkdir('chapters')
    os.chdir('chapters')
    for link in links:
        page = urllib.request.urlopen(link)
        soup = BeautifulSoup(page,'html5lib')
        title = namemodifier(soup.find(name='div', attrs={'class': "cha-tit"}).h3.string)
        cont = soup.find(name='div', attrs={'class': "cha-words"}).find_all(name='p')
        book.write(title+'\n')
        with open(title+'.txt','a+',encoding='utf-8') as f:
            for i in cont:
                try:
                    text = i.get_text()
                    text = text.strip()
                    if text == '\n' or text == '':
                        continue
                    elif not text.endswith('\n'):
                        text = text + '\n'
                    f.write(text)
                    book.write(text)
                except (TypeError,AttributeError):
                    pass
        print(now()+'Downloading %s' % title)
        time.sleep(0.1)
    book.close()

    # write logs
    readme.write('Book name: '+booktitle+'\n')
    readme.write('Original Author: '+bookinfo[0]+'\n')
    readme.write('Translator: '+bookinfo[1]+'\n')
    readme.write('Editor: '+bookinfo[2]+'\n')
    readme.write('\n')
    readme.write('© 2017 Webnovel\n')
    readme.write('Generated by Webnovel Crawler at '+now())
    readme.close()

    # Done!
    print('Work complete!')
    os.chdir('..\..')
    os.startfile(booktitle)
